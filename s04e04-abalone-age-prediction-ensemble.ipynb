{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":72489,"databundleVersionId":8096274,"sourceType":"competition"},{"sourceId":171711629,"sourceType":"kernelVersion"},{"sourceId":171846550,"sourceType":"kernelVersion"}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport warnings\nimport optuna\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.base import clone\nfrom sklearn.compose import TransformedTargetRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor, VotingRegressor\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\nfrom lightgbm import LGBMRegressor\n\nwarnings.filterwarnings('ignore')\nprint(\"1\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-14T01:57:17.677309Z","iopub.execute_input":"2024-04-14T01:57:17.677748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 27\nN_SPLITS = 10\nN_REPEATS = 5\nprint(\"2\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading and Processing Data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/playground-series-s4e4/train.csv', index_col='id')\ntest = pd.read_csv('/kaggle/input/playground-series-s4e4/test.csv', index_col='id')\n\ntrain['Sex'] = train['Sex'].map({'M': 0, 'F': 1, 'I': 2})\ntest['Sex'] = test['Sex'].map({'M': 0, 'F': 1, 'I': 2})\n\nX = train.drop(columns='Rings')\ny = train['Rings']\nprint(\"3\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Base Models","metadata":{}},{"cell_type":"code","source":"def train(regressor, X, y, n_splits=N_SPLITS, n_repeats=N_REPEATS):\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n    \n    model = TransformedTargetRegressor(\n        regressor=regressor,\n        func=np.log1p,\n        inverse_func=np.expm1\n    )\n    \n    oof_preds = np.zeros(len(X), dtype=float)\n    scores = []\n    for train_idx, val_idx in skf.split(X, y):\n        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n        \n        y_pred = np.zeros_like(y_val, dtype=float)\n        for i in range(n_repeats):\n            m = clone(model)\n            if n_repeats > 1:\n                m.regressor.set_params(random_state=i)\n            m.fit(X_train, y_train)\n            y_pred += m.predict(X_val)\n            \n        y_pred /= n_repeats\n        y_pred = y_pred.clip(1, 29)\n        \n        score = mean_squared_log_error(y_val, y_pred, squared=False)\n        scores.append(score)        \n        oof_preds[val_idx] = y_pred\n    \n    return scores, oof_preds\n\ndef predict(regressor, X, y, X_test, n_repeats=N_REPEATS):\n    model = TransformedTargetRegressor(\n        regressor=regressor,\n        func=np.log1p,\n        inverse_func=np.expm1\n    )\n    \n    y_pred = np.zeros(len(X_test), dtype=float)\n    for i in range(n_repeats):\n        m = clone(model)\n        if n_repeats > 1:\n            m.regressor.set_params(random_state=i)\n        m.fit(X, y)\n        y_pred += m.predict(X_test)\n    y_pred /= n_repeats\n    y_pred = y_pred.clip(1, 29)\n    return y_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_params = {\n    'n_jobs': -1,\n    'max_depth': 6,\n    'n_estimators': 1942,\n    'random_state': SEED,\n    'min_child_weight': 1,\n    'gamma': 0.03564293452391207,\n    'subsample': 0.6956271823055759,\n    'reg_alpha': 0.7236848478280202,\n    'reg_lambda': 0.6760094001242347,\n    'learning_rate': 0.04328457758575266,\n    'colsample_bynode': 0.962341555268564,\n    'colsample_bytree': 0.7506537997746077,\n    'colsample_bylevel': 0.8727635788126956,\n}\n\ncb_params = {\n    'depth': 15, \n    'verbose': 0,\n    'max_bin': 464, \n    'verbose': False,\n    'random_state':SEED,\n    'task_type': 'CPU', \n    'random_state': SEED,\n    'eval_metric': 'RMSE', \n    'min_data_in_leaf': 78, \n    'loss_function': 'RMSE', \n    'grow_policy': 'Lossguide', \n    'bootstrap_type': 'Bernoulli', \n    'subsample': 0.83862137638162, \n    'l2_leaf_reg': 8.365422739510098, \n    'random_strength': 3.296124856352495, \n    'learning_rate': 0.09992185242598203,\n}\n\nlgbm_params = {\n    'n_jobs': -1,\n    'verbose': -1,\n    'max_depth': 20,\n    'num_leaves': 165,\n    'subsample_freq': 1,\n    'random_state': SEED,\n    'n_estimators': 1460,\n    'min_child_samples': 25,\n    'reg_lambda': 6.13475387151606,\n    'subsample': 0.8036874216939632,\n    'reg_alpha': 0.3152990674231573,\n    'learning_rate': 0.009336479469693189,\n    'colsample_bytree': 0.5780931837049811,\n    'min_child_weight': 0.37333232256934057,\n}\n\ngb_params = {\n    'max_depth': 7,\n    'random_state': SEED,\n    'n_estimators': 1520,\n    'min_samples_leaf': 2,\n    'min_samples_split': 5,\n    'subsample': 0.8386058289444608,\n    'learning_rate': 0.021568657897174062,\n}","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_model = XGBRegressor(**xgb_params)\nxgb_scores, xgb_oof_preds = train(xgb_model, X, y)\nprint(f'XGB:    {np.mean(xgb_scores)}')\n\ncb_model = CatBoostRegressor(**cb_params)\ncb_scores, cb_oof_preds = train(cb_model, X, y)\nprint(f'CB:     {np.mean(cb_scores)}')\n\nlgbm_model = LGBMRegressor(**lgbm_params)\nlgbm_scores, lgbm_oof_preds = train(lgbm_model, X, y)\nprint(f'LGBM:   {np.mean(lgbm_scores)}')\n\ngb_model = GradientBoostingRegressor(**gb_params)\ngb_scores, gb_oof_preds = train(gb_model, X, y)\nprint(f'GB:     {np.mean(gb_scores)}')\nprint(\"4\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ensembling Base Learners","metadata":{}},{"cell_type":"code","source":"estimators = [\n    ('xgb', xgb_model),\n    ('cb', cb_model),\n    ('lgbm', lgbm_model),\n    ('gb', gb_model)\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def objective(trial):\n#     params = {\n#         'xgb_weight': trial.suggest_float('xgb_weight', 0.0, 1.0),\n#         'cb_weight': trial.suggest_float('cb_weight', 0.0, 1.0),\n#         'lgbm_weight': trial.suggest_float('lgbm_weight', 0.0, 1.0),\n#         'gb_weight': trial.suggest_float('gb_weight', 0.0, 1.0),\n#     }\n\n#     weights = [\n#         params['xgb_weight'],\n#         params['cb_weight'],\n#         params['lgbm_weight'],\n#         params['gb_weight']\n#     ]\n#     weights /= np.sum(weights)\n\n#     voter = VotingRegressor(estimators=estimators, weights=weights, n_jobs=-1)\n#     scores, _ = train(voter, X, y, 1)\n    \n#     return np.mean(scores)\n\n# study = optuna.create_study(direction='minimize')\n# study.optimize(objective, n_trials=1000)\n\n# best_weights = study.best_params\n# weights = [\n#     best_weights['xgb_weight'],\n#     best_weights['cb_weight'],\n#     best_weights['lgbm_weight'],\n#     best_weights['gb_weight']\n# ]\n\n# weights /= np.sum(weights)\n# print(f'\\nBest Weights: {list(weights)}')\n\n# weights = [0.08844250545656566, 0.6322423960522606, 0.2688203675689123, 0.0104947309222612189]\nweights = [0.25072415, 0.24954255, 0.24983537, 0.24989793]","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"voter = VotingRegressor(estimators=estimators, weights=weights, n_jobs=-1)\nvoter_scores, oof_preds = train(voter, X, y, N_SPLITS, 1)\n\nprint(f'Ensemble: {np.mean(voter_scores)}')\nprint(\"5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Results","metadata":{}},{"cell_type":"code","source":"scores = pd.DataFrame({\n    'XGB': xgb_scores,\n    'CB': cb_scores,\n    'LGBM': lgbm_scores,\n    'GB': gb_scores,\n    'Ensemble': voter_scores\n})\nscores = scores[scores.mean().sort_values().index]\n\nfig, axes = plt.subplots(1, 2, figsize=(15, 6))\nsns.boxplot(data=scores, ax=axes[0], palette='viridis')\naxes[0].set_title('Fold Scores')\naxes[0].set_xlabel('')\naxes[0].set_ylabel('')\nmean_scores = scores.mean().sort_values()\nsns.barplot(x=mean_scores, y=mean_scores.index, orient='h', ax=axes[1], palette='viridis')\naxes[1].set_title('Mean Scores')\naxes[1].set_xlabel('')\naxes[1].set_ylabel('')\naxes[1].set_xlim(left=0.147, right=0.1485)\nplt.tight_layout()\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Blending Results","metadata":{}},{"cell_type":"code","source":"y_pred = predict(voter, X, y, test, 1)\nvoter_sub = pd.DataFrame({'id': test.index, 'Rings': y_pred})\nvoter_sub.to_csv(f'xgb_cb_lgbm_gb_ensemble.csv', index=False)\nvoter_sub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"public_lb_best_sub = pd.read_csv('/kaggle/input/ps4e4-abalone-age-prediction-regression/submission_comb.csv')[\"Rings\"].values\nensemble_sub = voter_sub[\"Rings\"].values\n\nensemble_lb_sub = voter_sub.copy()\nensemble_lb_sub[\"Rings\"] = np.average(np.c_[public_lb_best_sub, ensemble_sub], axis=1, weights=[0.9, 0.1])\nensemble_lb_sub[\"Rings\"] = ensemble_lb_sub[\"Rings\"].clip(1, 29)\nensemble_lb_sub[\"Rings\"] = np.where(ensemble_lb_sub[\"Rings\"].between(27.5, 29), 29, ensemble_lb_sub[\"Rings\"])\nensemble_lb_sub.to_csv(f'xgb_cb_lgbm_gb_ensemble-public_lb_best.csv', index=False)\nensemble_lb_sub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier_sub = pd.read_csv('/kaggle/input/s04e04-abalone-age-prediction-classification/xgb_cb_ensemble.csv')[\"Rings\"].values\n\nensemble_lb_classifier_sub = voter_sub.copy()\nensemble_lb_classifier_sub[\"Rings\"] = np.average(np.c_[public_lb_best_sub, ensemble_sub, classifier_sub], axis=1, weights=[0.8, 0.1, 0.1])\nensemble_lb_classifier_sub[\"Rings\"] = ensemble_lb_classifier_sub[\"Rings\"].clip(1, 29)\nensemble_lb_classifier_sub[\"Rings\"] = np.where(ensemble_lb_classifier_sub[\"Rings\"].between(27.5, 29), 29, ensemble_lb_classifier_sub[\"Rings\"])\nensemble_lb_classifier_sub.to_csv(f'xgb_cb_lgbm_gb_ensemble-public_lb_best-classifier.csv', index=False)\nensemble_lb_classifier_sub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}